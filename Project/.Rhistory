residuals_sd <- eval_df %.>% .$residuals %.>% sd(., na.rm = T)
error_mean <- eval_df %.>% .$error %.>% mean(., na.rm = T)
error_sd <- eval_df %.>% .$error %.>% sd(., na.rm = T)
mae <- eval_df %.>% .$error %.>% abs(.) %.>% mean(., na.rm = T)
mape <- eval_df %.>% .$error_pct %.>% abs(.) %.>% mean(., na.rm = T)
mse <- eval_df %.>% .$error %.>% .^2 %.>% mean(., na.rm = T)
rmse <- mse %.>% sqrt(.)
# intervals
eval_df$ci_lo <- eval_df$forecasted - 1.96*residuals_sd #confidence
eval_df$ci_up <- eval_df$forecasted + 1.96*residuals_sd
eval_df$pi_lo <- eval_df$forecasted - 1.96*error_sd #prediction
eval_df$pi_up <- eval_df$forecasted + 1.96*error_sd
# plot results
theme_4panel <- function(base_size = 12,
base_family = ""){
theme_minimal(base_size = base_size,
base_family = base_family) %+replace%
theme(
axis.title.x = element_blank(),
axis.title.y = element_blank(),
plot.title = element_text(hjust=0.5, vjust=2, size=11),
panel.border = element_rect(color="black", fill=NA, size=.5),
legend.position = NULL,
legend.key.size = unit(1, "lines"),
legend.key.height = unit(0.7, "lines"),
legend.key.width = unit(0.7, "lines"),
legend.margin = margin(0, 0.1, 0.05, 0.1, "cm"),
legend.background = element_rect(color = 'black',
fill = 'white',
linetype = 'solid'),
legend.title = element_blank(),
legend.text = element_text(size = 10)
)
} #customizing theme_minimal()
#...training
p1 <- ggplot(eval_df[1:length(train),], aes(x=date)) +
geom_line(aes(y=raw, color="ts"), size=1) +
geom_line(aes(y=model, color="model"), size=1) +
labs(x=NULL, y='', title='Model') +
scale_color_manual(name="",
values=c("ts"="black",
"model"="#3399FF")) +
#might have to automate ylim again
ylim(c(-500, 15000))  +
theme_4panel() +
theme(legend.position = c(.075,.89)) +
scale_x_date(breaks="6 months", date_labels = "%b-%Y",
limits=c(eval_df$date[1], max=eval_df$date[length(train)]),
expand=c(0,0))
#...test
p2 <- ggplot(eval_df[length(train):length(eval_df$raw),], aes(x=date)) +
geom_ribbon(aes(ymin=pi_lo, ymax=pi_up), fill="blue", alpha=0.3) +
geom_ribbon(aes(ymin=ci_lo, ymax=ci_up), fill="lightblue", alpha=0.6) +
geom_line(aes(y=raw, color="ts"), size=1) +
geom_line(aes(y=forecasted, color="forecast"), size=1) +
labs(x='', y='', title='Forecast') +
scale_color_manual(name="",
values=c("ts"="black",
"forecast"="red")) +
ylim(c(-500, 15000)) +
theme_4panel() +
theme(legend.position = c(.91,.89)) +
scale_x_date(breaks="1 month", date_labels = "%b",
limits=c(eval_df$date[length(train)], max=max(eval_df$date)),
expand=c(0,0))
#...residuals
p3 <- ggplot(eval_df, aes(x=date)) +
geom_line(data = eval_df[1:length(train),],
aes(y=residuals, color="residuals"), size=1) +
geom_line(data = eval_df[length(train):length(eval_df$raw),],
aes(y=error, color="error"), size=1) +
labs(x='', y='', title='Residuals') +
scale_color_manual(name="",
values=c("residuals"="#3399FF",
"error"="red")) +
theme_4panel() +
theme(legend.position = c(.095,.89)) +
scale_x_date(breaks="6 months", date_labels = "%b-%Y",
limits=c(eval_df$date[1], max=max(eval_df$date)),
expand=c(0,0))
#...residuals distribution
p4 <- ggplot(eval_df) +
geom_density(data = eval_df[length(train):length(eval_df$raw),],
aes(x=error, color="error"), alpha=0.1, size=1, fill="red") +
geom_density(data = eval_df[1:length(train),],
aes(x=residuals, color="residuals"), alpha=0.2, size=1, fill="#3399FF") +
labs(x='', y='', title='Residuals Distribution') +
geom_vline(aes(xintercept=mean(error, na.rm=T), color="error"),
size=1, linetype="dashed") +
geom_vline(aes(xintercept=mean(residuals, na.rm=T), color="residuals"),
size=1, linetype="dashed") +
scale_color_manual(name="",
values=c("residuals"="#3399FF",
'error'="red")) +
scale_fill_manual(name="",
values=c('residuals'="#3399FF",
'error'="red")) +
theme_4panel() +
theme(legend.position = c(.905,.89))
# create subtitle reporting custom model specification
str_index <- function (forecast, start=NULL, stop=NULL, int=TRUE) {
#i=14,16,18 are standard seasonal parameters for forecast$method with ARIMA
if (int) {
as.integer(substr(forecast$method,
start=start,
stop=stop))
} else {
substr(forecast$method,
start=start,
stop=stop)
}
}
if (str_index(forecast, start=1, stop=5, int=F) == "ARIMA") {
first_s_value <- str_index(forecast, start=14,stop=14, int=F)
if (first_s_value != "" || !is.na(first_s_value)) {
#if expanding this for exogenous covariate series, condition "X" as well
cu.subtitle <- paste("S", sep = "", forecast$method)
}
} else {
cu.subtitle <- forecast$method
}
# display plot panel
(p1 + p2) /
(p3 + p4) +
plot_annotation(
title = 'Evaluation of Model Performance',
subtitle = paste('Model Specification:', sep=" ", cu.subtitle),
caption = glue('Training set :  n={length(train)} ({round(100*(length(train)/(length(train)+length(test))))}%)
Test set :         n={length(test)} ({round(100*(length(test)/(length(train)+length(test))))}%)'),
theme = theme(plot.title = element_text(hjust=0.5, size=15, face="bold"),
plot.subtitle = element_text(hjust=0.5, size=12)))
# Alternative color options:
# darkish green: #009900
# good blue: #3399FF
# thicker turquiose: #00CCCC
# deeper near-burghandy red: #CC3333
# brighter off-red: #FF6666
}
eval_forecast <- function (ts, forecast, test=test, train=train, console=TRUE,
assign.eval_tbl=FALSE, eval_tbl.name="eval_tbl",
print.eval_tbl=FALSE, return.eval_tbl = FALSE) {
# construct tmp df
eval_df <- tibble(raw = ts,
model = c(forecast$fitted, rep(NA, length(test))),   #NEED TO DROP/ADD THE +1 - used it for lstm
forecasted = c(rep(NA, length(train)), forecast$mean))
# residuals
eval_df$residuals <- eval_df$raw - eval_df$model  #i.e., forecast$residuals
eval_df$error <- eval_df$raw - eval_df$forecasted
eval_df$error_pct <- eval_df$error / eval_df$raw
# kpis
residuals_mean <- eval_df %.>% .$residuals %.>% mean(., na.rm = T)
residuals_sd <- eval_df %.>% .$residuals %.>% sd(., na.rm = T)
error_mean <- eval_df %.>% .$error %.>% mean(., na.rm = T)
error_sd <- eval_df %.>% .$error %.>% sd(., na.rm = T)
mae <- eval_df %.>% .$error %.>% abs(.) %.>% mean(., na.rm = T)
mape <- eval_df %.>% .$error_pct %.>% abs(.) %.>% mean(., na.rm = T)
mse <- eval_df %.>% .$error %.>% .^2 %.>% mean(., na.rm = T)
rmse <- mse %.>% sqrt(.)
# print results to console or to a table
#print to console
if (console) {
cat(glue("
------------------------------------
Evaluation of Algorithm Performance
------------------------------------
Training:
residuals mean: {round(residuals_mean)}
sd: {round(residuals_sd)}\n
Test:
error mean: {round(error_mean)}
sd: {round(error_sd)}
mae: {round(mae)}
mape: {round(mape*100)}%
mse: {round(mse)}
rmse: {round(rmse)}
test ratio:
test mean: {round(mean(test))}
rmse-mean ratio: {round(100*(rmse/mean(test)), 1)}%
------------------------------------"))
}
#create title reporting custom model specification
str_index <- function (forecast, start=NULL, stop=NULL, int=TRUE) {
#i=14,16,18 are standard seasonal parameters for forecast$method with ARIMA
if (int) {
as.integer(substr(forecast$method,
start=start,
stop=stop))
} else {
substr(forecast$method,
start=start,
stop=stop)
}
}
if (str_index(forecast, start=1, stop=5, int=F) == "ARIMA") {
first_s_value <- str_index(forecast, start=14,stop=14, int=F)
if (first_s_value != "" || !is.na(first_s_value)) {
#if expanding this for exogenous covariate series, condition "X" as well
cu.subtitle <- paste("S", sep = "", forecast$method)
}
} else {
cu.subtitle <- forecast$method
}
#create and assign table
eval_tbl <- tibble(
statistic=c("residuals_mean",
"residuals_sd",
"error_mean",
"error_sd",
"mae",
"mape.perc",
"mse",
"rmse",
"test_mean",
"rmse_test_mean_ratio.perc"),
values=c(round(residuals_mean),
round(residuals_sd),
round(error_mean),
round(error_sd),
round(mae),
round(mape*100),
round(mse),
round(rmse),
round(mean(test)),
round(100*(rmse/mean(test)), 1))
)
colnames(eval_tbl) <- c("Statistic", glue("{cu.subtitle}"))
if (assign.eval_tbl) {
assign(eval_tbl.name, eval_tbl, envir = .GlobalEnv)
} #declare user-defined tibble name
#conditioning output for a returned tibble for inline use
if (return.eval_tbl) {
return(eval_tbl)
}
#conditioning output for table to plot area
require(ggpmisc)
if (print.eval_tbl) {
ggplot() + geom_table_npc(data=eval_tbl, label=list(eval_tbl),
npcx=0.5, npcy=0.5, size=10) +
theme(plot.title = element_text(hjust=0.5, vjust=2, size=25))
}
}
# Execute testing functions
fc_accuracy_print(test, forecast)
eval_forecast(ts, forecast, test=test, train=train)
plot_eval_forecast(ts, forecast, test, train, og_df.date_col = ts_df$date)
# Check to see how tight the lags are within the residual CIs (ACF/PACF)
tsdisplay(residuals(fit_arima), lag.max=30, main='Seasonal Model Residuals')
blah <- eval_forecast(ms_ts, forecast, test, train, console=F, return.eval_tbl=F, print.eval_tbl = T)
blah
blah <- eval_forecast(ms_ts, forecast, test, train, console=F, return.eval_tbl=T, print.eval_tbl = F)
blah
eval_forecast(ms_ts, forecast, test, train, console=F, return.eval_tbl=F, print.eval_tbl = T)
fc_fn <- function (ts=ts, train_test_split = TRUE, split_perc=0.85,
fc_len=NULL, assign_fc_obj = c(FALSE, NULL),
eval_fc_output=c("report", "return fc object"),
modelvar=c("arima","tbats"),
autoarima=FALSE,
autoarima.spec = auto.arima(y = train, max.order = 20,
max.p = 10, max.d = 3, max.q = 10,
max.P = 10, max.D = 3, max.Q = 10,
stepwise = TRUE, seasonal = TRUE,
stationary = FALSE,
ic = "aic", trace = TRUE),
manual.arima.spec = arima(y = train,
order=c(2,1,0)),
manual.tbats.spec = tbats(y = train, trace = TRUE)) {
# create the training and test sets
if (train_test_split) {
train_test_split(ts, split_perc = split_perc)
} ### DO I NEED THE BOOLEAN HERE? i.e., SHOULDN'T I GIVE OPTION TO INPUT OWN TRAIN/TEST SETS?
# fit the model and create forecast object
if (modelvar == "arima") {
if (autoarima == TRUE) {
model <- autoarima.spec
} else {
# for seasonality, include seasonal=list(order=c(w,x,y, period=z) in manual.arima.spec()
model <- manual.arima.spec
}
} else if (modelvar == "tbats") {
model <- manual.tbats.spec
}
#allowing for manual forecast horizon
if (is.null(fc_len)) {
forecast <- forecast(model, h = length(test), level = c(80, 95, 99))
} else {
forecast <- forecast(model, h = fc_len, level = c(80, 95, 99))
}
# (optional) assign forecast to GlobalEnv w/ user-defined name
if (assign_fc_obj[1]) {
assign(assign_fc_obj[2], forecast, envir = .GlobalEnv)
}
# (optional) console & plot output, or assign forecast object:
#options: c(report", "return fc object")
if (any(eval_fc_output %like% c("report"))) {
eval_forecast(ts, forecast, test, train, console=T)
plot_eval_forecast(ts, forecast, test, train, og_df.date_col = ts_df$date)
} # else if (any(eval_fc_output %like% "return fc object")) {
#
# }
}
fc_fn(ts, modelvar = "arima", assign_fc_obj = c(TRUE, "fc.1"),
manual.arima.spec = arima(train,
order=c(2,1,6),
seasonal=list(order=c(1,1,1), period=7)),
eval_fc_output = "report")
fc_fn(ts, modelvar = "arima", assign_fc_obj = c(TRUE, "fc.1"),
manual.arima.spec = arima(train,
order=c(2,1,1),
seasonal=list(order=c(1,1,1), period=7)))
fc_fn(ts, modelvar = "arima", autoarima = TRUE, assign_fc_obj = c(TRUE, "fc.2"))
fc_fn(z_ts, modelvar = "arima", autoarima = TRUE, assign_fc_obj = c(TRUE, "fc.3"))
fc_fn(ms_ts, modelvar = "tbats", assign_fc_obj = c(TRUE, "fc.4"))
fc_fn(ts, modelvar = "arima", autoarima = TRUE, assign_fc_obj = c(TRUE, "fc.2"))
eval_forecast(ts, fc.1, test, train,console=F, assign.eval_tbl = T, eval_tbl.name = "tbl.1")
eval_forecast(ts, fc.2, test, train, console=F, assign.eval_tbl = T, eval_tbl.name = "tbl.2")
eval_forecast(z_ts, fc.3, test, train, console=F, assign.eval_tbl = T, eval_tbl.name = "tbl.3")
eval_forecast(ms_ts, fc.4, test, train, console=F, assign.eval_tbl = T, eval_tbl.name = "tbl.4")
tbl.final <- tibble(tbl.1, tbl.2[2], tbl.3[2], tbl.4[2])
ggplot() + geom_table_npc(data=tbl.final, label=list(tbl.final),
npcx=0.5, npcy=0.5, size=4,
table.theme=ttheme_gtstripes) + theme_minimal() +
theme(plot.title = element_text(hjust=0.5, vjust=2, size=11))
#third merge the tables for a ggplot table comparison of model
tbl.final <- tibble(tbl.1, tbl.2[2], tbl.3[2], tbl.4[2])
tbl.1
tbl.2
tbl.3
tbl.4
tbl.final <- tibble(tbl.1, tbl.2[2], tbl.4[2])
ggplot() + geom_table_npc(data=tbl.final, label=list(tbl.final),
npcx=0.5, npcy=0.5, size=4,
table.theme=ttheme_gtstripes) + theme_minimal() +
theme(plot.title = element_text(hjust=0.5, vjust=2, size=11))
ggplot.corr <- function(data, lag.max = 24, ci = 0.95, large.sample.size = TRUE, horizontal = TRUE,...) {
require(ggplot2)
require(dplyr)
require(cowplot)
if(horizontal == TRUE) {numofrow <- 1} else {numofrow <- 2}
list.acf <- acf(data, lag.max = lag.max, type = "correlation", plot = FALSE)
N <- as.numeric(list.acf$n.used)
df1 <- data.frame(lag = list.acf$lag, acf = list.acf$acf)
df1$lag.acf <- dplyr::lag(df1$acf, default = 0)
df1$lag.acf[2] <- 0
df1$lag.acf.cumsum <- cumsum((df1$lag.acf)^2)
df1$acfstd <- sqrt(1/N * (1 + 2 * df1$lag.acf.cumsum))
df1$acfstd[1] <- 0
df1 <- select(df1, lag, acf, acfstd)
list.pacf <- acf(data, lag.max = lag.max, type = "partial", plot = FALSE)
df2 <- data.frame(lag = list.pacf$lag,pacf = list.pacf$acf)
df2$pacfstd <- sqrt(1/N)
if(large.sample.size == TRUE) {
plot.acf <- ggplot(data = df1, aes( x = lag, y = acf)) +
geom_area(aes(x = lag, y = qnorm((1+ci)/2)*acfstd), fill = "#B9CFE7") +
geom_area(aes(x = lag, y = -qnorm((1+ci)/2)*acfstd), fill = "#B9CFE7") +
geom_col(fill = "#4373B6", width = 0.7) +
scale_x_continuous(breaks = seq(0,max(df1$lag),6)) +
scale_y_continuous(name = element_blank(),
limits = c(min(df1$acf,df2$pacf),1)) +
ggtitle("Autocorrelation (for MA component)") +
theme_bw()
plot.pacf <- ggplot(data = df2, aes(x = lag, y = pacf)) +
geom_area(aes(x = lag, y = qnorm((1+ci)/2)*pacfstd), fill = "#B9CFE7") +
geom_area(aes(x = lag, y = -qnorm((1+ci)/2)*pacfstd), fill = "#B9CFE7") +
geom_col(fill = "#4373B6", width = 0.7) +
scale_x_continuous(breaks = seq(0,max(df2$lag, na.rm = TRUE),6)) +
scale_y_continuous(name = element_blank(),
limits = c(min(df1$acf,df2$pacf),1)) +
ggtitle("Partial Autocorrelation (for AR component)") +
theme_bw()
}
else {
plot.acf <- ggplot(data = df1, aes( x = lag, y = acf)) +
geom_col(fill = "#4373B6", width = 0.7) +
geom_hline(yintercept = qnorm((1+ci)/2)/sqrt(N),
colour = "sandybrown",
linetype = "dashed") +
geom_hline(yintercept = - qnorm((1+ci)/2)/sqrt(N),
colour = "sandybrown",
linetype = "dashed") +
scale_x_continuous(breaks = seq(0,max(df1$lag),6)) +
scale_y_continuous(name = element_blank(),
limits = c(min(df1$acf,df2$pacf),1)) +
ggtitle("Autocorrelation (for MA component)") +
theme_bw()
plot.pacf <- ggplot(data = df2, aes(x = lag, y = pacf)) +
geom_col(fill = "#4373B6", width = 0.7) +
geom_hline(yintercept = qnorm((1+ci)/2)/sqrt(N),
colour = "sandybrown",
linetype = "dashed") +
geom_hline(yintercept = - qnorm((1+ci)/2)/sqrt(N),
colour = "sandybrown",
linetype = "dashed") +
scale_x_continuous(breaks = seq(0,max(df2$lag, na.rm = TRUE),6)) +
scale_y_continuous(name = element_blank(),
limits = c(min(df1$acf,df2$pacf),1)) +
ggtitle("Partial Autocorrelation (for AR component)") +
theme_bw()
}
cowplot::plot_grid(plot.acf, plot.pacf, nrow = numofrow)
}
p / ggplot.corr(ts_df$sales, lag.max = 30, ci=0.95)
ggplot.corr <- function(data, lag.max = 24, ci = 0.95, large.sample.size = TRUE, horizontal = TRUE,...) {
require(ggplot2)
require(dplyr)
require(cowplot)
if(horizontal == TRUE) {numofrow <- 1} else {numofrow <- 2}
list.acf <- acf(data, lag.max = lag.max, type = "correlation", plot = FALSE)
N <- as.numeric(list.acf$n.used)
df1 <- data.frame(lag = list.acf$lag, acf = list.acf$acf)
df1$lag.acf <- dplyr::lag(df1$acf, default = 0)
df1$lag.acf[2] <- 0
df1$lag.acf.cumsum <- cumsum((df1$lag.acf)^2)
df1$acfstd <- sqrt(1/N * (1 + 2 * df1$lag.acf.cumsum))
df1$acfstd[1] <- 0
df1 <- select(df1, lag, acf, acfstd)
list.pacf <- acf(data, lag.max = lag.max, type = "partial", plot = FALSE)
df2 <- data.frame(lag = list.pacf$lag,pacf = list.pacf$acf)
df2$pacfstd <- sqrt(1/N)
if(large.sample.size == TRUE) {
plot.acf <- ggplot(data = df1, aes( x = lag, y = acf)) +
geom_area(aes(x = lag, y = qnorm((1+ci)/2)*acfstd), fill = "#B9CFE7") +
geom_area(aes(x = lag, y = -qnorm((1+ci)/2)*acfstd), fill = "#B9CFE7") +
geom_col(fill = "#4373B6", width = 0.7) +
scale_x_continuous(breaks = seq(0,max(df1$lag),6)) +
scale_y_continuous(name = element_blank(),
limits = c(min(df1$acf,df2$pacf),1)) +
ggtitle("Autocorrelation (for MA component)") +
theme_bw()
plot.pacf <- ggplot(data = df2, aes(x = lag, y = pacf)) +
geom_area(aes(x = lag, y = qnorm((1+ci)/2)*pacfstd), fill = "#B9CFE7") +
geom_area(aes(x = lag, y = -qnorm((1+ci)/2)*pacfstd), fill = "#B9CFE7") +
geom_col(fill = "#4373B6", width = 0.7) +
scale_x_continuous(breaks = seq(0,max(df2$lag, na.rm = TRUE),6)) +
scale_y_continuous(name = element_blank(),
limits = c(min(df1$acf,df2$pacf),1)) +
ggtitle("Partial Autocorrelation (for AR component)") +
theme_bw()
}
else {
plot.acf <- ggplot(data = df1, aes( x = lag, y = acf)) +
geom_col(fill = "#4373B6", width = 0.7) +
geom_hline(yintercept = qnorm((1+ci)/2)/sqrt(N),
colour = "sandybrown",
linetype = "dashed") +
geom_hline(yintercept = - qnorm((1+ci)/2)/sqrt(N),
colour = "sandybrown",
linetype = "dashed") +
scale_x_continuous(breaks = seq(0,max(df1$lag),6)) +
scale_y_continuous(name = element_blank(),
limits = c(min(df1$acf,df2$pacf),1)) +
ggtitle("Autocorrelation (for MA component)") +
theme_bw()
plot.pacf <- ggplot(data = df2, aes(x = lag, y = pacf)) +
geom_col(fill = "#4373B6", width = 0.7) +
geom_hline(yintercept = qnorm((1+ci)/2)/sqrt(N),
colour = "sandybrown",
linetype = "dashed") +
geom_hline(yintercept = - qnorm((1+ci)/2)/sqrt(N),
colour = "sandybrown",
linetype = "dashed") +
scale_x_continuous(breaks = seq(0,max(df2$lag, na.rm = TRUE),6)) +
scale_y_continuous(name = element_blank(),
limits = c(min(df1$acf,df2$pacf),1)) +
ggtitle("Partial Autocorrelation (for AR component)") +
theme_bw()
}
cowplot::plot_grid(plot.acf, plot.pacf)
}
p / ggplot.corr(ts_df$sales, lag.max = 30, ci=0.95)
ggplot.corr(ts_df$sales, lag.max = 30, ci=0.95)
fit_arima <- arima(train,
order=c(2,1,1),
seasonal=list(order=c(1,1,1), period=7))  #abt as good as I can get it w/ zoo obj
# Check to see how tight the lags are within the residual CIs (ACF/PACF)
tsdisplay(residuals(fit_arima), lag.max=30, main='Seasonal Model Residuals')
# p / ggplot.corr(ts_df$sales, lag.max = 30, ci=0.95)
ggplot.corr(ts_df$sales, lag.max = 30, ci=0.95)
fc_accuracy_print(test, forecast)
plot_acf_pacf(ts_df, ci=0.95, diff=T)
runApp()
fit_arima <- arima(train,
order=c(2,1,0),
seasonal=list(order=c(2,1,0), period=7))  #pretty much trash
train <- train_test_split(ts, split_perc = 0.85, out.train = T)
test <- train_test_split(ts, split_perc = 0.85, out.test = T)
fit_arima <- arima(train,
order=c(2,1,0),
seasonal=list(order=c(2,1,0), period=7))  #pretty much trash
tsdisplay(residuals(fit_arima), lag.max=30, main='Seasonal Model Residuals')
forecast <- forecast(fit_arima, h = length(test), level = c(80, 95, 99))
fc_accuracy_print(test, forecast)
eval_forecast(ts, forecast, test=test, train=train)
eval_forecast(ts, forecast, test=test, train=train, console=F, print.eval_tbl=T)
plot_eval_forecast(ts, forecast, test, train, og_df.date_col = ts_df$date)
# Execute testing functions (eval_forecast() and plot_eval_forecast() are defined below)
fc_accuracy_print(test, forecast)
tsdisplay(residuals(fit_arima), lag.max=30, main='Seasonal Model Residuals')
# Forecast & plot
forecast <- forecast(fit_arima, h = length(test), level = c(80, 95, 99))
# Execute testing functions (eval_forecast() and plot_eval_forecast() are defined below)
fc_accuracy_print(test, forecast)
eval_forecast(ts, forecast, test=test, train=train, console=F, print.eval_tbl=T)
plot_eval_forecast(ts, forecast, test, train, og_df.date_col = ts_df$date)
eval_tbl_arima <- eval_forecast(ts, forecast, test=test, train=train, console=F, return.eval_tbl = T)
eval_tbl_arima
# Execute testing functions (eval_forecast() and plot_eval_forecast() are defined below)
#eval_tbl_arima <- eval_forecast(ts, forecast, test=test, train=train, console=F, return.eval_tbl=T, print.eval_tbl=F)
#eval_tbl_arima
eval_forecast(ts, forecast, test=test, train=train, console=T, return.eval_tbl=F, print.eval_tbl=F)
fc_accuracy_print(test, forecast)
plot_eval_forecast(ts, forecast, test, train, og_df.date_col = ts_df$date)
runApp()
